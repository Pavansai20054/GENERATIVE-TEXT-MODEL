{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from models.gpt_generator import GPTGenerator\n",
    "from models.lstm_generator import LSTMModel\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] Verify GPU Availability\n",
    "print(\"=== GPU Verification ===\")\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"PyTorch current device: {torch.cuda.current_device()}\")\n",
    "print(f\"PyTorch device name: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"TensorFlow GPUs available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] GPT-2 Generation with GPU\n",
    "print(\"=== GPT-2 Generation ===\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark generation\n",
    "start_time = time.time()\n",
    "prompt = \"Artificial intelligence with GPU acceleration enables\"\n",
    "generated_text = gpt.generate_text(\n",
    "    prompt, \n",
    "    max_length=150, \n",
    "    temperature=0.8,\n",
    "    top_k=50\n",
    ")\n",
    "gpt_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generated in {gpt_time:.2f} seconds:\")\n",
    "print(generated_text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] LSTM Generation with GPU\n",
    "print(\"=== LSTM Generation ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "with open('data/sample_texts.txt', 'r') as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "lstm = LSTMModel(text, seq_length=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data (only use first 50k chars for demo)\n",
    "X, y = lstm.prepare_data(text[:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (reduced epochs for demo)\n",
    "print(\"Starting training (3 epochs for demo)...\")\n",
    "start_time = time.time()\n",
    "lstm.train(X, y, epochs=3, batch_size=256)\n",
    "train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "start_time = time.time()\n",
    "seed = \"deep learning with gpus\"\n",
    "generated = lstm.generate_text(seed, length=200, temperature=0.6)\n",
    "lstm_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Trained in {train_time:.2f} seconds\")\n",
    "print(f\"Generated in {lstm_time:.2f} seconds:\")\n",
    "print(generated)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] Performance Comparison\n",
    "print(\"=== Performance Summary ===\")\n",
    "print(f\"GPT-2 Generation Time: {gpt_time:.2f}s\")\n",
    "print(f\"LSTM Training Time (3 epochs): {train_time:.2f}s\")\n",
    "print(f\"LSTM Generation Time: {lstm_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] GPU Memory Cleanup\n",
    "torch.cuda.empty_cache()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGPU memory cleared. Notebook execution complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
